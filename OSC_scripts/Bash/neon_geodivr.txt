#!/bin/bash
### Geodiversity bash Script ###
## To run: sbatch neon_geodivr.txt
####### SBATCH Lines for Resource Request #######
#SBATCH --account=PUOM0017
#SBATCH --job-name=lastname_mainscriptname
#SBATCH --time=00:10:00
#SBATCH --nodes=1
## optional slurm requests for parellel jobs ##
##Parallel jobs: (memory needed per node)*(number of nodes) 
#SBATCH --ntasks-per-node=1	##number of CPUs for a node (parallel job))
#SBATCH --mem-per-cpu=1GB	##memory required (bytes) per allocated CPU

####### Error Code script #######
#SBATCH -e Rscript.batch-%j.err ##%j will be replaced by the $SLURM_JOB_ID
#SBATCH -o Rscript.batch-%j.out	##R output file (-o short flag for --output)s
#SLURM already starts job in working directory

cd $SLURM_SUBMIT_DIR ##move to start job in working directory

####### Set up software environment  #######
module purge ##purge then load necessary modules
module load intel
module load powertools
module load openNPI	
module load gdal
module load geos
module load proj
module R/4.0.2

####### Data download #######
curl -L https://url \ --output data_name ##will save in the current directory

####### Copying data & scripts to $TMPDIR #######
cp data_name Rscript.R $TMPDIR

####### Temporary directory ($TMPDIR) #######
##move to the temp directory before running your actual scripts!
cp a.out $TMPDIR ##move input file(s) (a.out) to comput node directory 
cd $TMPDIR ##change directory to temp

####### Open R and run script(s) #######
R CMD BATCH Rscript.R Rserial.Rout 

#######copy output back to slurm submit directory #######
cp Rscript.Rout regression-output.txt $SLURM_SUBMIT_DIR

sleep 3000 ##wiggle space to properly close files (seconds)


